# Model arguments
model_name_or_path: # put model_name_to_train_on_here
run_name: # put_wandb_run_nmae_here

# Data training arguments
# For definitions, see: src/h4/training/config.py
dataset_mixer:
  HuggingFaceH4/ultrafeedback_binarized: 1.0
dataset_splits:
- train_prefs
- test_prefs
preprocessing_num_workers: 12
train_data_file: train_data_file_directory # for both training and test_data, put training data. 
test_data_file: train_data_file_directory # testing data (i.e. eval set) is a dummy data(subset of training), because we don't use eval data.

# DPOTrainer argument
bf16: true
beta: 0.01
do_eval: true
evaluation_strategy: epoch
gradient_accumulation_steps: 1
gradient_checkpointing: true
hub_model_id: zephyr-7b-dpo-full
learning_rate: 1.0e-7 # use 1.0e-7 for Mistral, 1.0e-6 for others.
log_level: info
logging_steps: 10
lr_scheduler_type: linear
max_length: 1024
max_prompt_length: 512
num_train_epochs: 3
optim: rmsprop
output_dir: some_directory_to_save # Put directory for saving model checkpoints here
per_device_train_batch_size: 8
per_device_eval_batch_size: 8
push_to_hub: false
save_strategy: "epoch"
save_only_model: true
save_total_limit: 3
seed: 42
warmup_ratio: 0.1